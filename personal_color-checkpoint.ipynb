{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original -> facecrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#★original -> facecrop\n",
    "import cv2\n",
    "#얼굴 검출과 눈 검출을 위한 HaarCascade트레이닝 데이터를 읽어 CascadeClassifier객체를 생성\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('uploads/original.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#CascadeClassifier의 detectMultiScale함수에 grayscale 이미지를 입력하여 얼굴을 검출\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "imgNum  = 0\n",
    "#얼굴이 검출되면 위치(x,y,w,h)를 return //x,y는 얼굴의 좌상단 위치//w,h는 가로,세로 크기\n",
    "for (x,y,w,h) in faces: \n",
    "    cropped = img[y - int(h / 4):y + h + int(h / 4), x - int(w / 4):x + w + int(w / 4)]\n",
    "    cropped = cv2.resize(cropped, (350,350))\n",
    "    cv2.imwrite(\"uploads/facecrop\" + \".jpg\", cropped)\n",
    "    imgNum += 1\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# facecrop -> outface(eyebrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#★facecrop -> outface(eyebrow)\n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "import numpy as np\n",
    "import collections\n",
    "import dlib\n",
    "import cv2\n",
    "def face_remap(shape):\n",
    "    remapped_image = cv2.convexHull(shape) #여러 점의 좌표를 이용하여 채워진 볼록 다각형을 그림\n",
    "    return remapped_image\n",
    "\n",
    "#입력 이미지 load -> 사이즈 변경-> grayscale로 변환\n",
    "image = cv2.imread(\"uploads/facecrop.jpg\")\n",
    "image = imutils.resize(image, width=350)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "out_face = np.zeros_like(image)\n",
    "# dlib's face detector(HOG-based)를 활성화시킨 후 facial landmark predictor를 생성\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "# grayscale 이미지의 얼굴을 검출한다.\n",
    "rects = detector(gray, 1)\n",
    "# loop over the face detections\n",
    "for (i, rect) in enumerate(rects):\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "   #mask array 활성화\n",
    "    remapped_shape = np.zeros_like(shape) \n",
    "    feature_mask = np.zeros((image.shape[0], image.shape[1]))   \n",
    "   # 얼굴만을 검춯한다\n",
    "    remapped_shape = face_remap(shape)\n",
    "    cv2.fillConvexPoly(feature_mask, remapped_shape[0:27], 1)\n",
    "    feature_mask = feature_mask.astype(np.bool)\n",
    "    out_face[feature_mask] = image[feature_mask]\n",
    "    cv2.imwrite(\"uploads/outface.jpg\", out_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# facecrop -> outface(forehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#★facecrop -> outface(forehead)\n",
    "from imutils import face_utils\n",
    "import imutils\n",
    "import numpy as np\n",
    "import collections\n",
    "import dlib\n",
    "import cv2\n",
    "def face_remap(shape):\n",
    "    remapped_image = cv2.convexHull(shape)\n",
    "    return remapped_image\n",
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(\"uploads/facecrop.jpg\")\n",
    "image = imutils.resize(image, width=350)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "out_face = np.zeros_like(image)\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_81_face_landmarks.dat\")\n",
    "\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "# loop over the face detections\n",
    "for (i, rect) in enumerate(rects):\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "   #initialize mask array\n",
    "    remapped_shape = np.zeros_like(shape) \n",
    "    feature_mask = np.zeros((image.shape[0], image.shape[1]))   \n",
    "   # extract the face\n",
    "    remapped_shape = face_remap(shape)\n",
    "    cv2.fillConvexPoly(feature_mask, remapped_shape[0:27], 1)\n",
    "    feature_mask = feature_mask.astype(np.bool)\n",
    "    out_face[feature_mask] = image[feature_mask]\n",
    "    cv2.imwrite(\"uploads/outface_.jpg\", out_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outface -> skinbackground(eyebrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#★outface -> skinbackground(eyebrow)\n",
    "import numpy as np\n",
    "import cv2\n",
    "#outface가 skin2에 놓일 위치를 인자로 받음 //skinbg2의 (hpos, vpos)에 위치하게 됨\n",
    "def bitOperation(hpos, vpos):\n",
    "    img1 = cv2.imread(\"skin2.jpg\")\n",
    "    img2 = cv2.imread(\"uploads/outface.jpg\")\n",
    "    #outface 이미지의 크기를 구하고, 좌표(10,10)에서 (cols+10,rows+10)을 roi영역으로 잡음\n",
    "    rows, cols, channels = img2.shape\n",
    "    roi = img1[vpos:rows+vpos, hpos:cols+hpos]\n",
    "    #outface를 흑백으로 변환하고, mask를 생성 (흑,백으로 완전히 구분되는 mask와 그 반대의 mask생성)\n",
    "    img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    #Roi에서 outface에 해당하는 부분만 검정색으로 만들기\n",
    "    img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    # outface 이미지에서 outface 부분만 추출하기\n",
    "    img2_fg = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "    # outface 이미지 배경을 cv2.add로 투명으로 만들고(검정색없어짐) roi에 outface이미지 넣음\n",
    "    dst = cv2.add(img1_bg, img2_fg)\n",
    "    img1[vpos:rows+vpos, hpos:cols+hpos] = dst #생성된 이미지를 roi영역에 덮어씀\n",
    "    img1 = cv2.resize(img1, (350,350))\n",
    "    cv2.imwrite(\"uploads/skinbg2.jpg\",img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "#skinbg2 이미지의 10,10좌표에 위치하게 됨   \n",
    "bitOperation(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outface -> skinbackground(forehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#★outface -> skinbackground(forehead)\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def bitOperation(hpos, vpos):\n",
    "    img1 = cv2.imread(\"skin2.jpg\")\n",
    "    img2 = cv2.imread(\"uploads/outface_.jpg\")\n",
    "    \n",
    "    rows, cols, channels = img2.shape\n",
    "    roi = img1[vpos:rows+vpos, hpos:cols+hpos]\n",
    "    \n",
    "    img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    \n",
    "    img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    img2_fg = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "    \n",
    "    dst = cv2.add(img1_bg, img2_fg)\n",
    "    img1[vpos:rows+vpos, hpos:cols+hpos] = dst\n",
    "    \n",
    "    img1 = cv2.resize(img1, (350,350))\n",
    "    cv2.imwrite(\"uploads/skinbg2_.jpg\",img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "bitOperation(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def bitOperation(hpos, vpos):\n",
    "    img1 = cv2.imread(\"skin2.jpg\")\n",
    "    img2 = cv2.imread(\"uploads/outface_.jpg\")\n",
    "    \n",
    "    rows, cols, channels = img2.shape\n",
    "    roi = img1[vpos:rows+vpos, hpos:cols+hpos]\n",
    "    \n",
    "    img2gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    \n",
    "    img1_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    img2_fg = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "    \n",
    "    dst = cv2.add(img1_bg, img2_fg)\n",
    "    img1[vpos:rows+vpos, hpos:cols+hpos] = dst\n",
    "    \n",
    "    img1 = cv2.resize(img1, (350,350))\n",
    "    cv2.imwrite(\"uploads/skinbg2_.jpg\",img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "bitOperation(10,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
